{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing an Physics-informed neural network for the 1D Schrodinger equation using the PINN framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Including necessary libaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PINNFramework.PINN import Interface\n",
    "from torch.autograd import grad\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import scipy.io\n",
    "from pyDOE import lhs\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underlying PDE\n",
    "$f:=i h_{t}+0.5 h_{x x}+|h|^{2} h$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing needed functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchrodingerPINN(Interface):\n",
    "    def __init__(self, model, input_d, output_d, lb, ub):\n",
    "        super().__init__(model,input_d,output_d)\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        \n",
    "    def pde(self, x, u, derivatives):\n",
    "        u_xx = derivatives[:,0]\n",
    "        v_xx = derivatives[:,1]\n",
    "        _u = u[:,0]\n",
    "        _v = u[:,1]\n",
    "        real_part = - 0.5 * v_xx - (_u**2 - _v**2)*_v\n",
    "        imaginary_part= 0.5 * u_xx + (_u**2 + _v**2)*_u \n",
    "        result = torch.stack([real_part,imaginary_part],1)\n",
    "        return result\n",
    "        \n",
    "    def derivatives(self, u, x):\n",
    "        grads= torch.ones(x.shape[0])\n",
    "        pred_u = u[:,0]\n",
    "        pred_v = u[:,1]\n",
    "        J_u = grad(pred_u, x, create_graph=True, grad_outputs=grads)[0]\n",
    "        J_v = grad(pred_v, x, create_graph=True, grad_outputs=grads)[0]\n",
    "        \n",
    "        #calculate first order derivatives\n",
    "        u_x = J_u[:,0]\n",
    "        u_t = J_u[:,1]\n",
    "\n",
    "        v_x = J_v[:,0]\n",
    "        v_t = J_v[:,1]\n",
    "        \n",
    "        # calculate second order derivatives\n",
    "        J_u_x = grad(u_x, x, create_graph=True, grad_outputs=grads)[0]\n",
    "        J_v_x = grad(v_x, x, create_graph=True, grad_outputs=grads)[0]\n",
    "\n",
    "        u_xx = J_u_x[:,0]\n",
    "        v_xx = J_v_x[:,0]\n",
    "        pred_derivatives = torch.stack([u_xx,v_xx,u_t,v_t],1)\n",
    "        return pred_derivatives\n",
    "    \n",
    "        \n",
    "    def input_normalization(self,x):\n",
    "        \"\"\"\n",
    "        Implementation of min-max scaling in range of [-1,1]\n",
    "        \"\"\"\n",
    "        return 2.0 * (x - self.lb) / (self.ub - self.lb) - 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Creating a model with the sequential API from torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinn_model = nn.Sequential(\n",
    "          nn.Linear(2,100),\n",
    "          nn.Tanh(),\n",
    "          nn.Linear(100,100),\n",
    "          nn.Tanh(),\n",
    "          nn.Linear(100,2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = torch.tensor([-5.0, 0.0])\n",
    "ub = torch.tensor([[5.0, np.pi / 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SchrodingerPINN(model = pinn_model, input_d = 2, output_d = 2, lb = lb, ub= ub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing forward function of the model (testing normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_x = torch.randn(100,2)\n",
    "sample_pred = model(sample_x)\n",
    "sample_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data (implement your dataset here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.0\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Doman bounds\n",
    "lb = np.array([-5.0, 0.0])  # lower bound consists of [lower bound of x, lower bound of t]\n",
    "ub = np.array([5.0, np.pi / 2])  # upper bound follows from lower bound\n",
    "\n",
    "# defines the sizes of the neural network\n",
    "N0 = 50\n",
    "N_b = 50\n",
    "N_f = 20000\n",
    "\n",
    "data = scipy.io.loadmat('/home/stille15/AIPP/Data/NLS.mat')\n",
    "\n",
    "\n",
    "t = data['tt'].flatten()[:, None]  # get timestamps\n",
    "x = data['x'].flatten()[:, None]  # get x positions\n",
    "Exact = data['uu']\n",
    "# definie labels\n",
    "Exact_u = np.real(Exact)\n",
    "Exact_v = np.imag(Exact)\n",
    "Exact_h = np.sqrt(Exact_u ** 2 + Exact_v ** 2)\n",
    "\n",
    "X, T = np.meshgrid(x, t)\n",
    "\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))  # concats the arrays\n",
    "u_star = Exact_u.T.flatten()[:, None]  #\n",
    "v_star = Exact_v.T.flatten()[:, None]\n",
    "h_star = Exact_h.T.flatten()[:, None]\n",
    "\n",
    "###########################\n",
    "\n",
    "idx_x = np.random.choice(x.shape[0], N0, replace=False)\n",
    "idx_x = np.sort(idx_x)\n",
    "\n",
    "x0 = x[idx_x, :]\n",
    "u0 = Exact_u[idx_x, 0:1]\n",
    "v0 = Exact_v[idx_x, 0:1]\n",
    "\n",
    "idx_t = np.random.choice(t.shape[0], N_b, replace=False)\n",
    "idx_t = np.sort(idx_t)\n",
    "tb = t[idx_t, :]\n",
    "\n",
    "x_f = lb + (ub - lb) * lhs(2, N_f) # determine sampling points \n",
    "t0 = torch.zeros([x0.shape[0],1])\n",
    "\n",
    "X_lb = np.concatenate((0 * tb + lb[0], tb), 1)  # (lb[0], tb)\n",
    "X_ub = np.concatenate((0 * tb + ub[0], tb), 1)  # (ub[0], tb)\n",
    "\n",
    "x_b = np.vstack((X_lb,X_ub)) # [x,t]\n",
    "x_0 = np.concatenate([x0,t0],1)\n",
    "u_b = np.zeros(x_b.shape)\n",
    "u_0 = np.concatenate([u0,v0],1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input_data dictionary and transfer data to torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {\"x_0\": torch.tensor(x_0).float(), \"x_b\": torch.tensor(x_b).float(), \"x_f\":torch.tensor(x_f).float()}\n",
    "u_0 = torch.tensor(u_0).float()\n",
    "u_b = torch.tensor(u_b).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Optimizer for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training_loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 17.6609230042:\n",
      "Epoch 2 Loss 16.6173038483:\n",
      "Epoch 3 Loss 15.6132755280:\n",
      "Epoch 4 Loss 14.6480093002:\n",
      "Epoch 5 Loss 13.7200527191:\n",
      "Epoch 6 Loss 12.8274488449:\n",
      "Epoch 7 Loss 11.9682512283:\n",
      "Epoch 8 Loss 11.1406841278:\n",
      "Epoch 9 Loss 10.3431282043:\n",
      "Epoch 10 Loss 9.5742053986:\n",
      "Epoch 11 Loss 8.8328800201:\n",
      "Epoch 12 Loss 8.1185379028:\n",
      "Epoch 13 Loss 7.4310216904:\n",
      "Epoch 14 Loss 6.7706074715:\n",
      "Epoch 15 Loss 6.1379303932:\n",
      "Epoch 16 Loss 5.5339021683:\n",
      "Epoch 17 Loss 4.9596123695:\n",
      "Epoch 18 Loss 4.4162387848:\n",
      "Epoch 19 Loss 3.9049463272:\n",
      "Epoch 20 Loss 3.4268074036:\n",
      "Epoch 21 Loss 2.9827165604:\n",
      "Epoch 22 Loss 2.5733277798:\n",
      "Epoch 23 Loss 2.1990065575:\n",
      "Epoch 24 Loss 1.8598101139:\n",
      "Epoch 25 Loss 1.5554894209:\n",
      "Epoch 26 Loss 1.2855019569:\n",
      "Epoch 27 Loss 1.0490258932:\n",
      "Epoch 28 Loss 0.8449721336:\n",
      "Epoch 29 Loss 0.6719809771:\n",
      "Epoch 30 Loss 0.5284147263:\n",
      "Epoch 31 Loss 0.4123407602:\n",
      "Epoch 32 Loss 0.3215260506:\n",
      "Epoch 33 Loss 0.2534451187:\n",
      "Epoch 34 Loss 0.2053197175:\n",
      "Epoch 35 Loss 0.1741889119:\n",
      "Epoch 36 Loss 0.1570124477:\n",
      "Epoch 37 Loss 0.1507886350:\n",
      "Epoch 38 Loss 0.1526682526:\n",
      "Epoch 39 Loss 0.1600456983:\n",
      "Epoch 40 Loss 0.1706181020:\n",
      "Epoch 41 Loss 0.1824155301:\n",
      "Epoch 42 Loss 0.1938108206:\n",
      "Epoch 43 Loss 0.2035185099:\n",
      "Epoch 44 Loss 0.2105906010:\n",
      "Epoch 45 Loss 0.2144089043:\n",
      "Epoch 46 Loss 0.2146726996:\n",
      "Epoch 47 Loss 0.2113705575:\n",
      "Epoch 48 Loss 0.2047378421:\n",
      "Epoch 49 Loss 0.1951972544:\n",
      "Epoch 50 Loss 0.1832952797:\n",
      "Epoch 51 Loss 0.1696418077:\n",
      "Epoch 52 Loss 0.1548607349:\n",
      "Epoch 53 Loss 0.1395555437:\n",
      "Epoch 54 Loss 0.1242872477:\n",
      "Epoch 55 Loss 0.1095590293:\n",
      "Epoch 56 Loss 0.0958037078:\n",
      "Epoch 57 Loss 0.0833706930:\n",
      "Epoch 58 Loss 0.0725128353:\n",
      "Epoch 59 Loss 0.0633783415:\n",
      "Epoch 60 Loss 0.0560106337:\n",
      "Epoch 61 Loss 0.0503577515:\n",
      "Epoch 62 Loss 0.0462904721:\n",
      "Epoch 63 Loss 0.0436250120:\n",
      "Epoch 64 Loss 0.0421456248:\n",
      "Epoch 65 Loss 0.0416235887:\n",
      "Epoch 66 Loss 0.0418311469:\n",
      "Epoch 67 Loss 0.0425506756:\n",
      "Epoch 68 Loss 0.0435819551:\n",
      "Epoch 69 Loss 0.0447470918:\n",
      "Epoch 70 Loss 0.0458957292:\n",
      "Epoch 71 Loss 0.0469089523:\n",
      "Epoch 72 Loss 0.0477005653:\n",
      "Epoch 73 Loss 0.0482167900:\n",
      "Epoch 74 Loss 0.0484323017:\n",
      "Epoch 75 Loss 0.0483455658:\n",
      "Epoch 76 Loss 0.0479736924:\n",
      "Epoch 77 Loss 0.0473475233:\n",
      "Epoch 78 Loss 0.0465084873:\n",
      "Epoch 79 Loss 0.0455050692:\n",
      "Epoch 80 Loss 0.0443903506:\n",
      "Epoch 81 Loss 0.0432179868:\n",
      "Epoch 82 Loss 0.0420389175:\n",
      "Epoch 83 Loss 0.0408976488:\n",
      "Epoch 84 Loss 0.0398298427:\n",
      "Epoch 85 Loss 0.0388613716:\n",
      "Epoch 86 Loss 0.0380080789:\n",
      "Epoch 87 Loss 0.0372772999:\n",
      "Epoch 88 Loss 0.0366690271:\n",
      "Epoch 89 Loss 0.0361774191:\n",
      "Epoch 90 Loss 0.0357914791:\n",
      "Epoch 91 Loss 0.0354963876:\n",
      "Epoch 92 Loss 0.0352746546:\n",
      "Epoch 93 Loss 0.0351071693:\n",
      "Epoch 94 Loss 0.0349753983:\n",
      "Epoch 95 Loss 0.0348624103:\n",
      "Epoch 96 Loss 0.0347539559:\n",
      "Epoch 97 Loss 0.0346390717:\n",
      "Epoch 98 Loss 0.0345096923:\n",
      "Epoch 99 Loss 0.0343606658:\n",
      "Epoch 100 Loss 0.0341890939:\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    loss = model.pinn_loss(x, u_0, u_b,interpolation_criterion=nn.MSELoss(), boundary_criterion=nn.MSELoss(), pde_norm=nn.MSELoss())\n",
    "    loss.backward()\n",
    "    print(\"Epoch %d Loss %.10f:\"%(epoch + 1, loss.item()))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
